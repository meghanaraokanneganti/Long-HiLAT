{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d59dfc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (0.15.12)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (8.0.4)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (3.1.40)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (2.28.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (5.9.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (1.33.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (6.0)\n",
      "Requirement already satisfied: pathtools in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (59.5.0)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (4.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from wandb) (3.20.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from Click!=8.0.0,>=7.1->wandb) (0.4.5)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2022.9.14)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -otobuf (c:\\users\\mkanneganti\\anaconda3\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22e43af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts:\n",
      "38.93     2139\n",
      "401.9     3233\n",
      "414.01    1921\n",
      "427.31    1992\n",
      "428       2115\n",
      "dtype: int64\n",
      "\n",
      "Label Percentages:\n",
      "38.93     34.611650\n",
      "401.9     52.313916\n",
      "414.01    31.084142\n",
      "427.31    32.233010\n",
      "428       34.223301\n",
      "dtype: float64\n",
      "      hadm_id                                      CombinedChunk  \\\n",
      "0      137090  date of birth:               sex:   m service ...   \n",
      "1      166588  date of birth:               sex:   f service ...   \n",
      "2      195209  date of birth:          sex:  m service csu ad...   \n",
      "3      133416  date of birth:               sex:   m service ...   \n",
      "4      173812  date of birth:               sex:   m service ...   \n",
      "...       ...                                                ...   \n",
      "6175   109483  date of birth:          sex:  m service illnes...   \n",
      "6176   109365  date of birth:                    sex: service...   \n",
      "6177   134157  date of birth:        sex:  f servicehospital ...   \n",
      "6178   183373  service neurology history this is a year old r...   \n",
      "6179   183363  date of birth:                    sex: service...   \n",
      "\n",
      "               labels  \n",
      "0     [1, 1, 0, 0, 0]  \n",
      "1     [0, 0, 0, 1, 1]  \n",
      "2     [0, 1, 1, 0, 1]  \n",
      "3     [1, 0, 0, 0, 0]  \n",
      "4     [1, 0, 0, 0, 0]  \n",
      "...               ...  \n",
      "6175  [1, 0, 0, 0, 0]  \n",
      "6176  [0, 1, 0, 0, 0]  \n",
      "6177  [1, 1, 0, 0, 0]  \n",
      "6178  [0, 1, 1, 1, 0]  \n",
      "6179  [0, 1, 0, 0, 0]  \n",
      "\n",
      "[6180 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from transformers import LongformerTokenizerFast, LongformerModel, LongformerConfig, Trainer, TrainingArguments, EvalPrediction, AutoTokenizer, AutoModel\n",
    "from transformers.models.longformer.modeling_longformer import LongformerPreTrainedModel, LongformerClassificationHead\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "# import wandb\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import ast\n",
    "# read the dataframe\n",
    "train = pd.read_csv('../data/mimic3/5/train_data_5_level_1.csv')\n",
    "train['Chunk1'] = train['Chunk1'].fillna('')\n",
    "train['Chunk2'] = train['Chunk2'].fillna('')\n",
    "train['Chunk3'] = train['Chunk3'].fillna('')\n",
    "train['Chunk4'] = train['Chunk4'].fillna('')\n",
    "train['Chunk5'] = train['Chunk5'].fillna('')\n",
    "train['Chunk6'] = train['Chunk6'].fillna('')\n",
    "train['Chunk7'] = train['Chunk7'].fillna('')\n",
    "train['Chunk8'] = train['Chunk8'].fillna('')\n",
    "train['Chunk9'] = train['Chunk9'].fillna('')\n",
    "train['Chunk10'] = train['Chunk10'].fillna('')\n",
    "\n",
    "# Concatenate the 'Chunk' columns into a single 'CombinedChunk' column\n",
    "train['CombinedChunk'] = train['Chunk1'] + train['Chunk2'] + train['Chunk3'] + train['Chunk4'] + train['Chunk5'] + train['Chunk6'] + train['Chunk7'] + train['Chunk8'] + train['Chunk9'] + train['Chunk10']\n",
    "train = train.drop(['Chunk1', 'Chunk2', 'Chunk3', 'Chunk4', 'Chunk5', 'Chunk6', 'Chunk7', 'Chunk8', 'Chunk9', 'Chunk10'], axis=1)\n",
    "train\n",
    "column_order = ['hadm_id', 'CombinedChunk', '38.93', '401.9', '414.01', '427.31', '428']\n",
    "\n",
    "train = train[column_order]\n",
    "\n",
    "train = train[column_order]\n",
    "\n",
    "# Extract the label columns\n",
    "label_columns = ['38.93', '401.9', '414.01', '427.31', '428']\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = train[label_columns].sum()\n",
    "\n",
    "# Display the counts for each label\n",
    "print(\"Label Counts:\")\n",
    "print(label_counts)\n",
    "\n",
    "label_percentages = label_counts / len(train) * 100\n",
    "\n",
    "# Display the percentages for each label\n",
    "print(\"\\nLabel Percentages:\")\n",
    "print(label_percentages)\n",
    "train['labels'] = train[train.columns[2:]].values.tolist()\n",
    "train = train.drop(['38.93', '401.9', '414.01', '427.31', '428'], axis=1)\n",
    "print(train)\n",
    "\n",
    "# train['labels'] = train['labels'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "# labels_df = pd.DataFrame(train['labels'].tolist(), columns=['38.93', '401.9', '414.01', '427.31', '428'])\n",
    "\n",
    "\n",
    "# label_counts = labels_df.sum()\n",
    "\n",
    "# print(\"Label Counts:\")\n",
    "# print(label_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3bfc7f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts:\n",
      "38.93     402\n",
      "401.9     778\n",
      "414.01    435\n",
      "427.31    470\n",
      "428       422\n",
      "dtype: int64\n",
      "\n",
      "Label Percentages:\n",
      "38.93     29.602356\n",
      "401.9     57.290133\n",
      "414.01    32.032401\n",
      "427.31    34.609720\n",
      "428       31.075110\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>CombinedChunk</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>142423</td>\n",
       "      <td>date of birth:               sex:   m service ...</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>187232</td>\n",
       "      <td>date of birth:               sex:   f service ...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199859</td>\n",
       "      <td>date of birth:               sex:   f service ...</td>\n",
       "      <td>[0, 0, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135343</td>\n",
       "      <td>date of birth:               sex:   m service ...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>191783</td>\n",
       "      <td>date of birth:               sex:   m service ...</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>103310</td>\n",
       "      <td>date of birth:               sex:   m service ...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>101071</td>\n",
       "      <td>date of birth:               sex:   f service ...</td>\n",
       "      <td>[0, 1, 1, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>124309</td>\n",
       "      <td>date of birth:               sex:   f service ...</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>129034</td>\n",
       "      <td>date of birth:               sex:   m service ...</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>158927</td>\n",
       "      <td>date of birth:               sex:   f service ...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1358 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id                                      CombinedChunk  \\\n",
       "0      142423  date of birth:               sex:   m service ...   \n",
       "1      187232  date of birth:               sex:   f service ...   \n",
       "2      199859  date of birth:               sex:   f service ...   \n",
       "3      135343  date of birth:               sex:   m service ...   \n",
       "4      191783  date of birth:               sex:   m service ...   \n",
       "...       ...                                                ...   \n",
       "1353   103310  date of birth:               sex:   m service ...   \n",
       "1354   101071  date of birth:               sex:   f service ...   \n",
       "1355   124309  date of birth:               sex:   f service ...   \n",
       "1356   129034  date of birth:               sex:   m service ...   \n",
       "1357   158927  date of birth:               sex:   f service ...   \n",
       "\n",
       "               labels  \n",
       "0     [1, 0, 0, 0, 0]  \n",
       "1     [0, 1, 0, 0, 0]  \n",
       "2     [0, 0, 1, 1, 1]  \n",
       "3     [0, 1, 0, 0, 0]  \n",
       "4     [1, 0, 0, 0, 0]  \n",
       "...               ...  \n",
       "1353  [0, 1, 0, 0, 0]  \n",
       "1354  [0, 1, 1, 0, 0]  \n",
       "1355  [1, 0, 0, 0, 0]  \n",
       "1356  [0, 0, 0, 1, 0]  \n",
       "1357  [0, 1, 0, 0, 0]  \n",
       "\n",
       "[1358 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the 'test' DataFrame from a CSV file (replace '/path/to/test_data.csv' with the actual path)\n",
    "test = pd.read_csv('../data/mimic3/5/test_data_5_level_1.csv')\n",
    "\n",
    "# Fill NaN values in 'Chunk' columns with empty strings\n",
    "test['Chunk1'] = test['Chunk1'].fillna('')\n",
    "test['Chunk2'] = test['Chunk2'].fillna('')\n",
    "test['Chunk3'] = test['Chunk3'].fillna('')\n",
    "test['Chunk4'] = test['Chunk4'].fillna('')\n",
    "test['Chunk5'] = test['Chunk5'].fillna('')\n",
    "test['Chunk6'] = test['Chunk6'].fillna('')\n",
    "test['Chunk7'] = test['Chunk7'].fillna('')\n",
    "test['Chunk8'] = test['Chunk8'].fillna('')\n",
    "test['Chunk9'] = test['Chunk9'].fillna('')\n",
    "test['Chunk10'] = test['Chunk10'].fillna('')\n",
    "\n",
    "# Concatenate the 'Chunk' columns into a single 'CombinedChunk' column\n",
    "test['CombinedChunk'] = test['Chunk1'] + test['Chunk2'] + test['Chunk3'] + test['Chunk4'] + test['Chunk5'] + test['Chunk6'] + test['Chunk7'] + test['Chunk8'] + test['Chunk9'] + test['Chunk10']\n",
    "test = test.drop(['Chunk1', 'Chunk2', 'Chunk3', 'Chunk4', 'Chunk5', 'Chunk6', 'Chunk7', 'Chunk8', 'Chunk9', 'Chunk10'], axis=1)\n",
    "\n",
    "# Define the desired column order for 'test' (similar to 'train')\n",
    "column_order = ['hadm_id', 'CombinedChunk', '38.93', '401.9', '414.01', '427.31', '428']\n",
    "\n",
    "# Reorder the columns in the 'test' DataFrame based on the specified order\n",
    "test = test[column_order]\n",
    "\n",
    "label_columns = ['38.93', '401.9', '414.01', '427.31', '428']\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = test[label_columns].sum()\n",
    "\n",
    "# Display the counts for each label\n",
    "print(\"Label Counts:\")\n",
    "print(label_counts)\n",
    "\n",
    "label_percentages = label_counts / len(test) * 100\n",
    "\n",
    "# Display the percentages for each label\n",
    "print(\"\\nLabel Percentages:\")\n",
    "print(label_percentages)\n",
    "\n",
    "# Create a 'labels' column in 'test' (if needed)\n",
    "test['labels'] = test[test.columns[2:]].values.tolist()\n",
    "test = test.drop(['38.93', '401.9', '414.01', '427.31', '428'], axis=1)\n",
    "test\n",
    "# Now, you have performed the same operations on the 'test' DataFrame as you did for 'train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d295b8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts:\n",
      "38.93     333\n",
      "401.9     708\n",
      "414.01    388\n",
      "427.31    396\n",
      "428       337\n",
      "dtype: int64\n",
      "\n",
      "Label Percentages:\n",
      "38.93     27.773144\n",
      "401.9     59.049208\n",
      "414.01    32.360300\n",
      "427.31    33.027523\n",
      "428       28.106756\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>CombinedChunk</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143537</td>\n",
       "      <td>date of birth:               sex:   m service ...</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>167925</td>\n",
       "      <td>date of birth:               sex:   m service ...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150956</td>\n",
       "      <td>date of birth:               sex:   m service ...</td>\n",
       "      <td>[1, 0, 0, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180164</td>\n",
       "      <td>service medicine allergies patient recorded as...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>180767</td>\n",
       "      <td>date of birth:               sex:   f service ...</td>\n",
       "      <td>[0, 1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>188594</td>\n",
       "      <td>date of birth:               sex:   m service ...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>151432</td>\n",
       "      <td>service neurosurgery allergies patient recorde...</td>\n",
       "      <td>[0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>152868</td>\n",
       "      <td>date of birth:               sex:   m service ...</td>\n",
       "      <td>[0, 1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197</th>\n",
       "      <td>180431</td>\n",
       "      <td>date of birth:               sex:   f service ...</td>\n",
       "      <td>[1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>111912</td>\n",
       "      <td>date of birth:               sex:   f service ...</td>\n",
       "      <td>[0, 1, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hadm_id                                      CombinedChunk  \\\n",
       "0      143537  date of birth:               sex:   m service ...   \n",
       "1      167925  date of birth:               sex:   m service ...   \n",
       "2      150956  date of birth:               sex:   m service ...   \n",
       "3      180164  service medicine allergies patient recorded as...   \n",
       "4      180767  date of birth:               sex:   f service ...   \n",
       "...       ...                                                ...   \n",
       "1194   188594  date of birth:               sex:   m service ...   \n",
       "1195   151432  service neurosurgery allergies patient recorde...   \n",
       "1196   152868  date of birth:               sex:   m service ...   \n",
       "1197   180431  date of birth:               sex:   f service ...   \n",
       "1198   111912  date of birth:               sex:   f service ...   \n",
       "\n",
       "               labels  \n",
       "0     [1, 0, 0, 0, 0]  \n",
       "1     [0, 1, 0, 0, 0]  \n",
       "2     [1, 0, 0, 1, 1]  \n",
       "3     [0, 1, 0, 0, 0]  \n",
       "4     [0, 1, 1, 1, 0]  \n",
       "...               ...  \n",
       "1194  [0, 1, 0, 0, 0]  \n",
       "1195  [0, 0, 0, 1, 0]  \n",
       "1196  [0, 1, 0, 0, 0]  \n",
       "1197  [1, 0, 0, 0, 0]  \n",
       "1198  [0, 1, 1, 1, 0]  \n",
       "\n",
       "[1199 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the 'dev' DataFrame from a CSV file (replace '/path/to/dev_data.csv' with the actual path)\n",
    "dev = pd.read_csv('../data/mimic3/5/dev_data_5_level_1.csv')\n",
    "\n",
    "# Fill NaN values in 'Chunk' columns with empty strings\n",
    "dev['Chunk1'] = dev['Chunk1'].fillna('')\n",
    "dev['Chunk2'] = dev['Chunk2'].fillna('')\n",
    "dev['Chunk3'] = dev['Chunk3'].fillna('')\n",
    "dev['Chunk4'] = dev['Chunk4'].fillna('')\n",
    "dev['Chunk5'] = dev['Chunk5'].fillna('')\n",
    "dev['Chunk6'] = dev['Chunk6'].fillna('')\n",
    "dev['Chunk7'] = dev['Chunk7'].fillna('')\n",
    "dev['Chunk8'] = dev['Chunk8'].fillna('')\n",
    "dev['Chunk9'] = dev['Chunk9'].fillna('')\n",
    "dev['Chunk10'] = dev['Chunk10'].fillna('')\n",
    "\n",
    "# Concatenate the 'Chunk' columns into a single 'CombinedChunk' column\n",
    "dev['CombinedChunk'] = dev['Chunk1'] + dev['Chunk2'] + dev['Chunk3'] + dev['Chunk4'] + dev['Chunk5'] + dev['Chunk6'] + dev['Chunk7'] + dev['Chunk8'] + dev['Chunk9'] + dev['Chunk10']\n",
    "dev = dev.drop(['Chunk1', 'Chunk2', 'Chunk3', 'Chunk4', 'Chunk5', 'Chunk6', 'Chunk7', 'Chunk8', 'Chunk9', 'Chunk10'], axis=1)\n",
    "\n",
    "# Define the desired column order for 'dev' (similar to 'train' and 'test')\n",
    "column_order = ['hadm_id', 'CombinedChunk', '38.93', '401.9', '414.01', '427.31', '428']\n",
    "\n",
    "# Reorder the columns in the 'dev' DataFrame based on the specified order\n",
    "dev = dev[column_order]\n",
    "\n",
    "label_columns = ['38.93', '401.9', '414.01', '427.31', '428']\n",
    "\n",
    "# Count the occurrences of each label\n",
    "label_counts = dev[label_columns].sum()\n",
    "\n",
    "# Display the counts for each label\n",
    "print(\"Label Counts:\")\n",
    "print(label_counts)\n",
    "\n",
    "label_percentages = label_counts / len(dev) * 100\n",
    "\n",
    "# Display the percentages for each label\n",
    "print(\"\\nLabel Percentages:\")\n",
    "print(label_percentages)\n",
    "\n",
    "# Create a 'labels' column in 'dev' (if needed)\n",
    "dev['labels'] = dev[dev.columns[2:]].values.tolist()\n",
    "dev = dev.drop(['38.93', '401.9', '414.01', '427.31', '428'], axis=1)\n",
    "dev\n",
    "# Now, you have performed the same operations on the 'dev' DataFrame as you did for 'train' and 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "09b69754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongformerForMultiLabelICDClassification(LongformerPreTrainedModel):\n",
    "    \"\"\"\n",
    "    We instantiate a class of LongFormer adapted for a multilabel classification task.\n",
    "    This instance takes the pooled output of the LongFormer based model and passes it through a classification head. We replace the traditional Cross Entropy loss with a BCE loss that generate probabilities for all the labels that we feed into the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(LongformerForMultiLabelICDClassification, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.transformer_layer = AutoModel.from_pretrained(\"pretrained/ClinicalplusXLNet/\")\n",
    "        self.longformer = LongformerModel(config)\n",
    "        self.classifier = LongformerClassificationHead(config)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, global_attention_mask=None,\n",
    "                token_type_ids=None, position_ids=None, inputs_embeds=None,\n",
    "                labels=None):\n",
    "\n",
    "        # create global attention on sequence, and a global attention token on the `s` token\n",
    "        # the equivalent of the CLS token on BERT models. This is taken care of by HuggingFace\n",
    "        # on the LongformerForSequenceClassification class\n",
    "        if global_attention_mask is None:\n",
    "            global_attention_mask = torch.zeros_like(input_ids)\n",
    "            global_attention_mask[:, 0] = 1\n",
    "        #transformer_output = self.transformer_layer(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\n",
    "        # pass arguments to longformer model\n",
    "        #transformer_output = tuple(torch.tensor(tf.convert_to_tensor(hs)).detach().numpy() for hs in transformer_output.hidden_states)\n",
    "        outputs = self.longformer(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            global_attention_mask = global_attention_mask,\n",
    "            token_type_ids = token_type_ids,\n",
    "            position_ids = position_ids)\n",
    "\n",
    "        # if specified the model can return a dict where each key corresponds to the output of a\n",
    "        # LongformerPooler output class. In this case we take the last hidden state of the sequence\n",
    "        # which will have the shape (batch_size, sequence_length, hidden_size).\n",
    "        sequence_output = outputs['last_hidden_state']\n",
    "\n",
    "        # pass the hidden states through the classifier to obtain thee logits\n",
    "        logits = self.classifier(sequence_output)\n",
    "        outputs = (logits,) + outputs[2:]\n",
    "        if labels is not None:\n",
    "            loss_fct = BCEWithLogitsLoss()\n",
    "            labels = labels.float()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels),\n",
    "                            labels.view(-1, self.num_labels))\n",
    "            #outputs = (loss,) + outputs\n",
    "            outputs = (loss,) + outputs\n",
    "\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cedbdf43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "class Data_Processing(object):\n",
    "    def __init__(self, tokenizer, id_column, text_column, label_column):\n",
    "\n",
    "        # define the text column from the dataframe\n",
    "        self.text_column = text_column.tolist()\n",
    "\n",
    "        # define the label column and transform it to list\n",
    "        self.label_column = label_column\n",
    "\n",
    "        # define the id column and transform it to list\n",
    "        self.id_column = id_column.tolist()\n",
    "\n",
    "\n",
    "# iter method to get each element at the time and tokenize it using bert\n",
    "    def __getitem__(self, index):\n",
    "        comment_text = str(self.text_column[index])\n",
    "        comment_text = \" \".join(comment_text.split())\n",
    "        # encode the sequence and add padding\n",
    "        inputs = tokenizer.encode_plus(comment_text,\n",
    "                                       add_special_tokens = True,\n",
    "                                       max_length= 3048,\n",
    "                                       padding = 'max_length',\n",
    "                                       return_attention_mask = True,\n",
    "                                       truncation = True,\n",
    "                                       return_tensors='pt')\n",
    "        input_ids = inputs['input_ids']\n",
    "        attention_mask = inputs['attention_mask']\n",
    "\n",
    "        labels_ = torch.tensor(self.label_column[index], dtype=torch.float)\n",
    "        id_ = self.id_column[index]\n",
    "        return {'input_ids':input_ids[0], 'attention_mask':attention_mask[0],\n",
    "                'labels':labels_, 'id_':id_}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_column)\n",
    "\n",
    "batch_size = 2\n",
    "# create a class to process the training and test data\n",
    "tokenizer = AutoTokenizer.from_pretrained('yikuan8/Clinical-Longformer',\n",
    "                                                    padding = 'max_length',\n",
    "                                                    truncation=False,\n",
    "                                                    max_length = 4096,\n",
    "                                                    padding_side=\"right\")\n",
    "training_data = Data_Processing(tokenizer,\n",
    "                                train['hadm_id'],\n",
    "                                train['CombinedChunk'],\n",
    "                                train['labels'])\n",
    "dev_data = Data_Processing(tokenizer,\n",
    "                             dev['hadm_id'],\n",
    "                             dev['CombinedChunk'],\n",
    "                             dev['labels'])\n",
    "test_data =  Data_Processing(tokenizer,\n",
    "                             test['hadm_id'],\n",
    "                             test['CombinedChunk'],\n",
    "                             test['labels'])\n",
    "\n",
    "# use the dataloaders class to load the data\n",
    "dataloaders_dict = {'train': DataLoader(training_data, batch_size=batch_size, shuffle=True, num_workers=4),\n",
    "                    'val': DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "                   }\n",
    "\n",
    "dataset_sizes = {'train':len(training_data),\n",
    "                 'val':len(test_data)\n",
    "                }\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83dde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LongformerForMultiLabelICDClassification.from_pretrained('yikuan8/Clinical-Longformer',\n",
    "                                                  gradient_checkpointing=False,\n",
    "                                                  attention_window = 512,\n",
    "                                                  num_labels = 5,\n",
    "                                                  return_dict=True)\n",
    "\n",
    "model.to(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d871cf0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 58\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# instantiate the trainer class and check for available devices\u001b[39;00m\n\u001b[0;32m     48\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m     49\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     50\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \n\u001b[0;32m     56\u001b[0m )\n\u001b[1;32m---> 58\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     59\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py:1555\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1553\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1554\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1556\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   1557\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[0;32m   1558\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[0;32m   1559\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[0;32m   1560\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py:1860\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1857\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1860\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[0;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1863\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1864\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1865\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1866\u001b[0m ):\n\u001b[0;32m   1867\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py:2725\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2722\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2724\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2725\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[0;32m   2727\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2728\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\trainer.py:2748\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2747\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2748\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   2749\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2750\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[14], line 28\u001b[0m, in \u001b[0;36mLongformerForMultiLabelICDClassification.forward\u001b[1;34m(self, input_ids, attention_mask, global_attention_mask, token_type_ids, position_ids, inputs_embeds, labels)\u001b[0m\n\u001b[0;32m     24\u001b[0m     global_attention_mask[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#transformer_output = self.transformer_layer(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, output_hidden_states=True)\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# pass arguments to longformer model\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m#transformer_output = tuple(torch.tensor(tf.convert_to_tensor(hs)).detach().numpy() for hs in transformer_output.hidden_states)\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlongformer(\n\u001b[0;32m     29\u001b[0m     input_ids \u001b[38;5;241m=\u001b[39m input_ids,\n\u001b[0;32m     30\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m attention_mask,\n\u001b[0;32m     31\u001b[0m     global_attention_mask \u001b[38;5;241m=\u001b[39m global_attention_mask,\n\u001b[0;32m     32\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m token_type_ids,\n\u001b[0;32m     33\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m position_ids)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# if specified the model can return a dict where each key corresponds to the output of a\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# LongformerPooler output class. In this case we take the last hidden state of the sequence\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# which will have the shape (batch_size, sequence_length, hidden_size).\u001b[39;00m\n\u001b[0;32m     38\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast_hidden_state\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:1738\u001b[0m, in \u001b[0;36mLongformerModel.forward\u001b[1;34m(self, input_ids, attention_mask, global_attention_mask, head_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1730\u001b[0m extended_attention_mask: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_extended_attention_mask(attention_mask, input_shape)[\n\u001b[0;32m   1731\u001b[0m     :, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, :\n\u001b[0;32m   1732\u001b[0m ]\n\u001b[0;32m   1734\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[0;32m   1735\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds\n\u001b[0;32m   1736\u001b[0m )\n\u001b[1;32m-> 1738\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[0;32m   1739\u001b[0m     embedding_output,\n\u001b[0;32m   1740\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   1741\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m   1742\u001b[0m     padding_len\u001b[38;5;241m=\u001b[39mpadding_len,\n\u001b[0;32m   1743\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1744\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m   1745\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m   1746\u001b[0m )\n\u001b[0;32m   1747\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1748\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:1318\u001b[0m, in \u001b[0;36mLongformerEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, padding_len, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1307\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1308\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m   1309\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1315\u001b[0m         output_attentions,\n\u001b[0;32m   1316\u001b[0m     )\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1318\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m   1319\u001b[0m         hidden_states,\n\u001b[0;32m   1320\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1321\u001b[0m         layer_head_mask\u001b[38;5;241m=\u001b[39mhead_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1322\u001b[0m         is_index_masked\u001b[38;5;241m=\u001b[39mis_index_masked,\n\u001b[0;32m   1323\u001b[0m         is_index_global_attn\u001b[38;5;241m=\u001b[39mis_index_global_attn,\n\u001b[0;32m   1324\u001b[0m         is_global_attn\u001b[38;5;241m=\u001b[39mis_global_attn,\n\u001b[0;32m   1325\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1326\u001b[0m     )\n\u001b[0;32m   1327\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;66;03m# bzs x seq_len x num_attn_heads x (num_global_attn + attention_window_len + 1) => bzs x num_attn_heads x seq_len x (num_global_attn + attention_window_len + 1)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:1246\u001b[0m, in \u001b[0;36mLongformerLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1238\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1244\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1245\u001b[0m ):\n\u001b[1;32m-> 1246\u001b[0m     self_attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(\n\u001b[0;32m   1247\u001b[0m         hidden_states,\n\u001b[0;32m   1248\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1249\u001b[0m         layer_head_mask\u001b[38;5;241m=\u001b[39mlayer_head_mask,\n\u001b[0;32m   1250\u001b[0m         is_index_masked\u001b[38;5;241m=\u001b[39mis_index_masked,\n\u001b[0;32m   1251\u001b[0m         is_index_global_attn\u001b[38;5;241m=\u001b[39mis_index_global_attn,\n\u001b[0;32m   1252\u001b[0m         is_global_attn\u001b[38;5;241m=\u001b[39mis_global_attn,\n\u001b[0;32m   1253\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1254\u001b[0m     )\n\u001b[0;32m   1255\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m self_attn_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1256\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m self_attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:1182\u001b[0m, in \u001b[0;36mLongformerAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[0;32m   1172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   1173\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1174\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1180\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1181\u001b[0m ):\n\u001b[1;32m-> 1182\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself(\n\u001b[0;32m   1183\u001b[0m         hidden_states,\n\u001b[0;32m   1184\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   1185\u001b[0m         layer_head_mask\u001b[38;5;241m=\u001b[39mlayer_head_mask,\n\u001b[0;32m   1186\u001b[0m         is_index_masked\u001b[38;5;241m=\u001b[39mis_index_masked,\n\u001b[0;32m   1187\u001b[0m         is_index_global_attn\u001b[38;5;241m=\u001b[39mis_index_global_attn,\n\u001b[0;32m   1188\u001b[0m         is_global_attn\u001b[38;5;241m=\u001b[39mis_global_attn,\n\u001b[0;32m   1189\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m   1190\u001b[0m     )\n\u001b[0;32m   1191\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m   1192\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attn_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\longformer\\modeling_longformer.py:644\u001b[0m, in \u001b[0;36mLongformerSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, layer_head_mask, is_index_masked, is_index_global_attn, is_global_attn, output_attentions)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m attn_scores\n\u001b[0;32m    643\u001b[0m \u001b[38;5;66;03m# apply dropout\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m attn_probs \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(attn_probs, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m    646\u001b[0m value_vectors \u001b[38;5;241m=\u001b[39m value_vectors\u001b[38;5;241m.\u001b[39mview(seq_len, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    648\u001b[0m \u001b[38;5;66;03m# compute local attention output with global attention value and add\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\functional.py:1235\u001b[0m, in \u001b[0;36mdropout\u001b[1;34m(input, p, training, inplace)\u001b[0m\n\u001b[0;32m   1231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39madaptive_avg_pool3d(\u001b[38;5;28minput\u001b[39m, _output_size)\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;66;03m# Activation functions\u001b[39;00m\n\u001b[1;32m-> 1235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdropout\u001b[39m(\u001b[38;5;28minput\u001b[39m: Tensor, p: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m, training: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, inplace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;124;03m    During training, randomly zeroes some of the elements of the input\u001b[39;00m\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;124;03m    tensor with probability :attr:`p` using samples from a Bernoulli\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;124;03m        inplace: If set to ``True``, will do this operation in-place. Default: ``False``\u001b[39;00m\n\u001b[0;32m   1247\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28minput\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "\n",
    "def multi_label_metrics(predictions, labels):\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    probs = sigmoid(torch.Tensor(predictions))\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_true = labels\n",
    "    y_pred[np.where(probs >= 0.5)] = 1\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # define dictionary of metrics to return\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics\n",
    "\n",
    "# Use the aux EvalPrediction class to obtain prediction labels\n",
    "def compute_metrics(p: EvalPrediction):\n",
    "    preds = p.predictions[0] if isinstance(p.predictions,\n",
    "            tuple) else p.predictions\n",
    "    result = multi_label_metrics(\n",
    "        predictions=preds,\n",
    "        labels=p.label_ids)\n",
    "    return result\n",
    "\n",
    "# define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = '../model/new',\n",
    "    num_train_epochs = 1,\n",
    "    per_device_train_batch_size = 2,\n",
    "    gradient_accumulation_steps = 64,\n",
    "    per_device_eval_batch_size= 2,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    disable_tqdm = False,\n",
    "    load_best_model_at_end=False,\n",
    "    warmup_steps = 2000,\n",
    "    learning_rate = 2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps = 8,\n",
    "    fp16 = False,\n",
    "    logging_dir='/logs',\n",
    "    dataloader_num_workers = 0,\n",
    "    run_name = 'longformer_multilabel_paper_trainer_3048_2e5',\n",
    "    report_to = 'none'\n",
    ")\n",
    "# instantiate the trainer class and check for available devices\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=training_data,\n",
    "    eval_dataset=dev_data,\n",
    "    compute_metrics = compute_metrics,\n",
    "    #data_collator = Data_Processing(),\n",
    "\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597fa024",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = trainer.predict(test_dataset=test_data)\n",
    "test_metrics = compute_metrics(test_predictions)\n",
    "f1_scores_per_label = test_metrics['f1_scores_per_label']\n",
    "\n",
    "print(test_predictions)\n",
    "\n",
    "for label_idx, f1_score_label in f1_scores_per_label.items():\n",
    "    print(f\"F1-score for label {label_idx}: {f1_score_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a532fa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is running on cpu.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming `model` is your PyTorch model\n",
    "device = next(model.parameters()).device\n",
    "\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Model is running on CUDA (GPU).\")\n",
    "else:\n",
    "    print(f\"Model is running on {device.type}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474254e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
